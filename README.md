# Hybrid Pharmacokinetic Modelling for Vancomycin Model-Informed Precision Dosing

This repository contains the code for a hybrid pharmacokinetic (PK) / machine learning pipeline for vancomycin model-informed precision dosing (MIPD). Individual Bayesian-estimated PK parameters (CL, Vc) are inferred from clinical data using two published population PK models, then used as targets for machine learning models that predict PK parameters from routine patient covariates.

The pipeline is implemented across three stages: MAP Bayesian Estimation (MAP-BE) in R, and XGBoost and Symbolic Regression in Python. Each stage follows a shared-pipeline architecture — common logic lives in a single shared file, and model-specific scripts contain only what differs between the two PK models.

---

## Repository Structure

```
.
├── shared_pipeline_mapbe.R          # Shared data cleaning, MAP-BE runner, export utilities
├── 01_garibay2016_mapbe.R           # Garibay et al. (2016) PopPK model + MAP-BE
├── 02_goti2018_mapbe.R              # Goti et al. (2018) PopPK model + MAP-BE
│
├── shared_pipeline_xgboost.py       # Shared PK simulator, XGBoost tuning, plotting utilities
├── 01_garibay2016_xgboost.py        # Garibay XGBoost training and evaluation
├── 02_goti2018_xgboost.py           # Goti XGBoost training and evaluation
│
├── shared_pipeline_sr.py            # Shared PK simulator, PySR fitting loop, plotting utilities
├── 01_garibay2016_sr.py             # Garibay Symbolic Regression training and evaluation
└── 02_goti2018_sr.py                # Goti Symbolic Regression training and evaluation
```

---

## Data

All scripts expect the following input CSV files in the working directory:

| File | Description |
|---|---|
| `rrt_and_race.csv` | RRT status and race per admission |
| `demographics_original.csv` | Patient demographics (age, weight, sex, serum creatinine) |
| `vanco_administrations.csv` | Vancomycin dose administration records |
| `vanco_tdm.csv` | Therapeutic drug monitoring (TDM) observations |
| `ML_Dataset_GaribayFullFinal.csv` | Output of Garibay MAP-BE stage; input to ML stages |
| `ML_Dataset_GotiFullFinal.csv` | Output of Goti MAP-BE stage; input to ML stages |

Data are sourced from [MIMIC-IV](https://physionet.org/content/mimiciv/). Access requires credentialed PhysioNet registration. The processed ML datasets (`ML_Dataset_*.csv`) are generated by running the MAP-BE stage.

---

## Stage 1 — MAP Bayesian Estimation (R)

### Overview

For each patient admission, individual PK parameters (CL, Vc) are estimated via Maximum A Posteriori Bayesian Estimation (MAP-BE) using a two-compartment vancomycin population PK model. The estimated parameters and predicted trough concentrations are appended to the dataset and exported for use in the machine learning stages.

### Dependencies

Install R packages before running:

```r
install.packages(c("mapbayr", "mrgsolve", "dplyr", "ggplot2", "lubridate", "future.apply"))
```

### Files

**`shared_pipeline_mapbe.R`**

Sourced automatically by both model scripts. Contains:
- Data loading from CSV files
- Non-RRT patient filtering
- CRCL calculation (Cockcroft-Gault)
- Dosing list construction (time/amount pairs)
- Quality filters (≥3 doses, TDM ≥12 h post-first-dose, TDM >5 h post-last-dose)
- Z-score outlier removal (|Z| > 5)
- `run_mapbe()` — single-patient MAP-BE with error handling
- `run_mapbe_parallel()` — parallel execution across all patients
- `export_results()` — appends MAP-BE results and writes CSV

**`01_garibay2016_mapbe.R`** — Garibay et al. (2016)

Two-compartment model. CL scales linearly with CRCL. V1 uses an age-stratified typical value (≤65 vs >65 years) scaled by body weight. V2 scales with body weight. Q is fixed.

Key covariates: body weight (BW), creatinine clearance (CRCL, converted to L/h), age (AGE).

**`02_goti2018_mapbe.R`** — Goti et al. (2018)

Two-compartment model. CL scales with CRCL via a power function (exponent 0.8). V1 scales with body weight relative to a 70 kg reference. V2 is fixed. Dialysis status reduces TVCL by 30% and TVV1 by 50% (all patients here are non-dialysis by construction).

Key covariates: body weight (BW), creatinine clearance (CRCL, ml/min), dialysis status (DIAL).

### Running

Set the working directory to your data folder, then open and run either model script. The shared pipeline is sourced automatically:

```r
# In RStudio: open 01_garibay2016_mapbe.R and press Ctrl+Shift+Enter
# Or from the R console:
source("01_garibay2016_mapbe.R")
source("02_goti2018_mapbe.R")
```

Both scripts can be run in the same session. Each calls `rm(list = ls())` at the top to ensure a clean environment, then re-sources the shared pipeline.

### Outputs

| File | Description |
|---|---|
| `ML_Dataset_GaribayFullFinal.csv` | Patient data with MAP-BE CL, Vc, and predicted trough |
| `ML_Dataset_GotiFullFinal.csv` | Same, using the Goti model |

---

## Stage 2 — XGBoost (Python)

### Overview

XGBoost regression models are trained to predict individual MAP-BE CL and Vc from a broad set of routine clinical covariates. Hyperparameters are tuned using Optuna with 10-fold cross-validation. Predicted PK parameters are then passed through the two-compartment PK simulator to generate a predicted trough concentration, which is compared against the reference covariate-equation predictions.

### Dependencies

```bash
pip install xgboost scikit-learn optuna pandas numpy matplotlib scipy
```

### Files

**`shared_pipeline_xgboost.py`**

Imported by both model scripts via `from shared_pipeline_xgboost import *`. Contains:
- `load_and_clean()` — data loading and MAP-BE outlier removal
- `simulate_two_comp()` — two-compartment ODE solver for trough prediction
- `prediction_band()` — 95% prediction band for scatter plots
- `plot_distribution()`, `plot_pred_obs()`, `plot_feature_importance()` — plotting utilities
- `tune_and_train_xgb()` — Optuna hyperparameter search + final model fit
- `simulate_troughs()` — trough simulation loop over a set of patient indices
- `make_split()`, `get_test_indices()` — reproducible train/test splitting
- `print_metrics()` — RMSE and MAPE reporting

**`01_garibay2016_xgboost.py`** — Garibay et al. (2016)

Model-specific content:
- `CSV_PATH = "ML_Dataset_GaribayFullFinal.csv"`
- Covariate CL: `0.49 × (CRCL / 1000 × 60)`
- Covariate Vc: age-stratified (`1.07 × BW` if age >65, else `0.74 × BW`)
- Vp per patient: `5.90 × weight` (weight-dependent)
- Q = 0.81 L/h

**`02_goti2018_xgboost.py`** — Goti et al. (2018)

Model-specific content:
- `CSV_PATH = "ML_Dataset_GotiFullFinal.csv"`
- Covariate CL: `4.5 × (CRCL / 120)^0.8`
- Covariate Vc: `58.4 × (weight / 70)`
- Vp = 38.4 L (fixed)
- Q = 6.5 L/h

### Running

Place all files in the same directory as the ML dataset CSVs, then run:

```bash
python 01_garibay2016_xgboost.py
python 02_goti2018_xgboost.py
```

### Outputs

Each script produces console output of RMSE and R² metrics at each stage, and displays the following plots:
- MAP-BE CL and Vc distributions
- MAP-BE predicted vs observed trough
- Covariate-equation reference CL and Vc performance
- XGBoost CL and Vc performance (vs reference)
- Full and top-10 feature importance bar charts
- XGBoost trough concentration performance (vs reference)

---

## Stage 3 — Symbolic Regression (Python)

### Overview

PySR is used to discover interpretable mathematical expressions for CL and Vc from a curated subset of clinical features. The search is run over three random splits (75/25 train/test). All equations in the Pareto-optimal hall of fame are evaluated on the test set and exported to Excel for manual inspection. A chosen best equation is then applied to simulate trough concentrations on the fold-1 test set.

### Dependencies

```bash
pip install pysr scikit-learn pandas numpy matplotlib scipy torch
```

> PySR requires Julia. On first run it will install Julia and the required Julia packages automatically. This may take several minutes.

### Files

**`shared_pipeline_sr.py`**

Imported by both model scripts via `from shared_pipeline_sr import *`. Contains:
- `load_and_clean()` — data loading and MAP-BE outlier removal
- `set_seeds()` — seeds NumPy, Python random, and PyTorch simultaneously
- `simulate_two_comp()` — two-compartment ODE solver
- `prediction_band()` — 95% prediction band
- `compute_ref_troughs()` — reference trough simulation over full dataset
- `run_sr()` — PySR fitting loop with ShuffleSplit CV, equation evaluation, and Excel export
- `fold_metrics()` — per-fold RMSE and R² for reference comparison
- `plot_sr_trough()` — trough scatter plot with SR vs reference overlay
- `print_metrics()` — RMSE and MAPE reporting

**`01_garibay2016_sr.py`** — Garibay et al. (2016)

Model-specific content:
- `CSV_PATH = "ML_Dataset_GaribayFullFinal.csv"`
- `CL_FEATURES`: Age, Scr.Baseline, Weight, Gender, BUN, RDW, Mean.Temperature, Mean.SBP
- `VC_FEATURES`: Weight, Scr.Baseline
- PySR CL settings: `parsimony=0.15`, `maxsize=15`, `select_k_features=8`
- PySR Vc settings: `parsimony=20.0`, `maxsize=9`, `select_k_features=2`
- Best SR equations defined as `sr_CL(row)` and `sr_Vc(row)` — update these after inspecting the Excel output
- Outputs: `garibay_SR_CL_final_freek.xlsx`, `garibay_SR_Vc_final_freek.xlsx`

**`02_goti2018_sr.py`** — Goti et al. (2018)

Model-specific content:
- `CSV_PATH = "ML_Dataset_GotiFullFinal.csv"`
- `CL_FEATURES`: Age, Scr.Baseline, BUN, Weight, Albumin, Gender, Mean.SBP, RDW
- `VC_FEATURES`: Weight, Scr.Baseline
- Same PySR settings as Garibay
- Best SR equations defined as `sr_CL(row)` and `sr_Vc(row)`
- Outputs: `goti_SR_CL_final.xlsx`, `goti_SR_Vc_final.xlsx`

### Running

```bash
python 01_garibay2016_sr.py
python 02_goti2018_sr.py
```

### Workflow

1. Run the SR script — this searches for equations and saves all hall-of-fame candidates to Excel
2. Open the Excel file and select the best equation based on the Pareto front (complexity vs RMSE_test)
3. Paste the chosen equation into the `sr_CL(row)` and `sr_Vc(row)` functions in the model script
4. Re-run the trough simulation section to evaluate its clinical performance

### Outputs

| File | Description |
|---|---|
| `garibay_SR_CL_final_freek.xlsx` | Hall-of-fame CL equations across 3 folds (Garibay) |
| `garibay_SR_Vc_final_freek.xlsx` | Hall-of-fame Vc equations across 3 folds (Garibay) |
| `goti_SR_CL_final.xlsx` | Hall-of-fame CL equations across 3 folds (Goti) |
| `goti_SR_Vc_final.xlsx` | Hall-of-fame Vc equations across 3 folds (Goti) |

Each Excel file contains one sheet per fold, with columns: `equation`, `complexity`, `RMSE_train`, `RMSE_test`, `R2_test`.

---

## PK Models

| Parameter | Garibay et al. (2016) | Goti et al. (2018) |
|---|---|---|
| TVCL | 0.49 × CRCL [L/h] | 4.5 × (CRCL/120)^0.8 [L/h] |
| TVV1 | 1.07×BW (age>65) / 0.74×BW (age≤65) [L] | 58.4 × (BW/70) [L] |
| TVV2 | 5.90 × BW [L] | 38.4 [L] |
| Q | 0.81 [L/h] | 6.5 [L/h] |
| IIV (CL, V1) | ω² = 0.1264, 0.1484 | ω² = 0.147, 0.5103, 0.2822 |
| Residual error | Proportional + additive | Proportional + additive |

---

## References

- Medellin-Garibay SE et al. *Pharmacokinetics of vancomycin and dosing recommendations for trauma patients.* J Antimicrob Chemother.2016.
- Goti V et al. *Hospitalized Patients With and Without Hemodialysis Have Markedly Different Vancomycin Pharmacokinetics: A Population Pharmacokinetic Model-Based Analysis.* Ther Drug Monit. 2018.
- Johnson AEW et al. *MIMIC-IV, a freely accessible electronic health record dataset.* Sci Data. 2023.
- Chen T, Guestrin C. *XGBoost: A Scalable Tree Boosting System.* KDD. 2016.
- Cranmer M et al. *Discovering Symbolic Models from Deep Learning with Inductive Biases.* NeurIPS. 2020.
